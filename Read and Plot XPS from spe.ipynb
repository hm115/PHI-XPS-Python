{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the following 2 blocks. \n",
    "## Then, start where it says Step 1/6. Run all blocks unless specified otherwise.\n",
    "\n",
    "Make sure lmfit, ipympl, and ipywidgets are installed in your python environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1623175922772,
     "user": {
      "displayName": "Hansen Mou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpX0kAdNL6lFvVSEqTwcLfrTvr1l-z768ZLhGZ=s64",
      "userId": "05725151348395746586"
     },
     "user_tz": 240
    },
    "id": "5UECFNr8mttl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import array\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import re\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "\n",
    "from lmfit import Model\n",
    "\n",
    "import sys\n",
    "import tkinter\n",
    "from tkinter.filedialog import askopenfilenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1623175925642,
     "user": {
      "displayName": "Hansen Mou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpX0kAdNL6lFvVSEqTwcLfrTvr1l-z768ZLhGZ=s64",
      "userId": "05725151348395746586"
     },
     "user_tz": 240
    },
    "id": "OSSWTZLalUVz"
   },
   "outputs": [],
   "source": [
    "### The code block below is modified by Tiger Mou from the Python3convert-multipak-to-XPSPEAK-columbia.py file that was originally written by Robert Forest in Python 2, modified for Python 3 by Hansen Mou. Plotting and fitting was written by Hansen Mou.\n",
    "\n",
    "### This block imports the spe file.\n",
    "\n",
    "class XSpectrum:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._regions = []\n",
    "        self._XPS_REGION_START_STR = b'DP'\n",
    "        self._XPS_HEADER_SIZE = 42\n",
    "   \n",
    "    def load_xps(self, path):\n",
    "        \"\"\"\n",
    "        Read and parse XPS file according to the reverse engineering of\n",
    "        Robert Forest's Python3convert-multipak-to-XPSPEAK-columbia.py\n",
    "        \"\"\"\n",
    "        file_str = \"\"\n",
    "        # We read in the entire file because iterating through is tedious.\n",
    "        with open(path, 'rb') as f:\n",
    "            print('Reading XPS from ' + path)\n",
    "            file_str = f.read();\n",
    "            f.close()\n",
    "\n",
    "        version_str = file_str[0:11].decode('utf-8')\n",
    "        print(f'File version is: {version_str}')\n",
    "\n",
    "        idx = file_str.find(self._XPS_REGION_START_STR) + len(self._XPS_REGION_START_STR)\n",
    "        while idx != -1:\n",
    "            print(f'IDX: {idx}')\n",
    "            (region, size) = self.__xps_read_region(file_str, idx)\n",
    "            self._regions.append(region)\n",
    "            idx = file_str.find(self._XPS_REGION_START_STR, idx + size) + len(self._XPS_REGION_START_STR)\n",
    "\n",
    "        print('Done!')\n",
    "    \n",
    "  \n",
    "    def load_spe(self, path):\n",
    "        \"\"\"\n",
    "        Read and parse SPE file according to the reverse engineering of\n",
    "        Robert Forest's Python3convert-multipak-to-XPSPEAK-columbia.py\n",
    "        \"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            print('Reading SPE from ' + path)\n",
    "            num_regions = self.__spe_get_number_of_regions(f)\n",
    "            BE_parameters = self.__spe_get_BE_parameters(f, num_regions)\n",
    "            self.__spe_convert_multipak_file(f, BE_parameters, num_regions)\n",
    "        print('Done!')\n",
    "\n",
    "    # XPS helper functions\n",
    "    def __xps_read_region(self, file_str, idx):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        curr_reg = dict()\n",
    "\n",
    "        \"\"\" Header contains: (total 42 bytes)\n",
    "        0: region_size (2 bytes)\n",
    "        1: unknown: uint 655353 (4)\n",
    "        2: 20 characters for the region_name, with whitespace padding (20)\n",
    "        3: region_size again ?? (2)\n",
    "        4: unknown: int of 1 (2)\n",
    "        5: region_size + 1 (2)\n",
    "        and 10 zeros to end the header (10)\n",
    "        \"\"\"\n",
    "        region_header = struct.unpack_from('<HI20sHHH10x', file_str, idx)\n",
    "        print(region_header)\n",
    "        idx += self._XPS_HEADER_SIZE\n",
    "\n",
    "        curr_reg['region_size'] = region_header[0]\n",
    "        curr_reg['region_name'] = region_header[2].strip()\n",
    "        \n",
    "        # Read region be\n",
    "        curr_reg['be_data'] = np.array(struct.unpack_from(f'<{region_header[0]}f', file_str, idx))\n",
    "        idx += region_header[0] * 4\n",
    "\n",
    "        # Strange whitespace of 1, region_size+1, and 10 zeros\n",
    "        unknown_whitespace = struct.unpack_from('<HH10x', file_str, idx)\n",
    "        idx += 14\n",
    "\n",
    "        # Read region intensity\n",
    "        curr_reg['intensity'] = np.array(struct.unpack_from(f'<{region_header[0]}f', file_str, idx))\n",
    "        idx += region_header[0] * 4\n",
    "\n",
    "        \"\"\" Footer contains:\n",
    "        0: max_BE\n",
    "        1: min_BE\n",
    "        2: max_intensity\n",
    "        3: min_intensity\n",
    "        and LOTS of whitespace for some reason...\n",
    "        \"\"\"\n",
    "        region_footer = struct.unpack_from('<4f', file_str, idx)\n",
    "        idx += 76\n",
    "\n",
    "        curr_reg['max_be'] = region_footer[0]\n",
    "        curr_reg['min_be'] = region_footer[1]\n",
    "        curr_reg['max_intensity'] = region_footer[2]\n",
    "        curr_reg['min_intensity'] = region_footer[3]\n",
    "\n",
    "        # I think it's nothing but idk why\n",
    "        region_post_footers = []\n",
    "        for i in range(6):\n",
    "            region_post_footers.append(struct.unpack_from(f'<HH10x{region_header[0]}f', file_str, idx + i*18+region_header[0]*4))\n",
    "\n",
    "        curr_reg['post_footers'] = region_post_footers\n",
    "        \n",
    "        region_size = self._XPS_HEADER_SIZE + region_header[0] * 4 * 2 + 14 + 16 + (6 *(2+2+region_header[0]*4+10)) + 18\n",
    "\n",
    "        return (curr_reg, region_size)\n",
    "\n",
    "\n",
    "    # SPE helper functions\n",
    "\n",
    "    def __spe_get_number_of_regions(self, file):\n",
    "        \"\"\"\n",
    "        Returns the total number of elements (\"regions\") from multi-scan\n",
    "        \"\"\"\n",
    "        file_string = file.read()\n",
    "        i = file_string.rfind(b'NoSpectralReg: ') + len('NoSpectralReg: ')\n",
    "        file.seek(i)\n",
    "        return int(file.readline())\n",
    "\n",
    "    def __spe_get_BE_parameters(self, file, num_regions):\n",
    "        \"\"\"Returns a 2D list of binding energy parameters as strings\n",
    "        First dimension is the region number\n",
    "        Second dimension is a list of individual parameters for that region\n",
    "        Indices: 3-region name, 5-region size, 6-step size, 7-high BE, 8-low BE\n",
    "        \"\"\"\n",
    "        BE_parameters = []\n",
    "        for line_number in range(num_regions):\n",
    "            BE_parameters.append(file.readline())\n",
    "            BE_parameters[line_number] = BE_parameters[line_number].split(b' ')\n",
    "        return BE_parameters\n",
    "\n",
    "    def __spe_convert_multipak_file(self, file, BE_parameters, num_regions):\n",
    "        # Set up regions.\n",
    "        self._regions = [dict() for _ in range(num_regions)]\n",
    "\n",
    "        # Go to start of data in multipak file.\n",
    "        data_size = 0\n",
    "        for i in range(num_regions):\n",
    "            data_size += int(BE_parameters[i][5])\n",
    "        file.seek(-8 * data_size, 2) \n",
    "\n",
    "        # Process data in each region.\n",
    "        for i in range(num_regions):\n",
    "            # Reference to regions dict.\n",
    "            curr_reg = self._regions[i]\n",
    "\n",
    "            region_params = BE_parameters[i]\n",
    "            curr_reg['max_be'] = float(region_params[7])\n",
    "            curr_reg['min_be'] = float(region_params[8])\n",
    "            curr_reg['region_size'] = int(region_params[5])\n",
    "            intensity_data_double = array.array('d')\n",
    "            intensity_data_double.fromfile(file, curr_reg['region_size'])\n",
    "                        \n",
    "            # Region metadata.  Not sure if useful.\n",
    "            curr_reg['region_name'] = region_params[3]\n",
    "\n",
    "            # I guess XPS format doesn't support double?\n",
    "            curr_reg['be_data'] = np.linspace(curr_reg['max_be'], curr_reg['min_be'], curr_reg['region_size'])\n",
    "\n",
    "            curr_reg['intensity'] = np.array(intensity_data_double)\n",
    "\n",
    "            curr_reg['min_intensity'] = min(curr_reg['intensity'])\n",
    "            curr_reg['max_intensity'] = max(curr_reg['intensity'])\n",
    "\n",
    "def get_file_names():    \n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    root.attributes('-topmost',True)\n",
    "    file_list = askopenfilenames(parent=root, title='Open XPS files',\n",
    "                                              filetypes=[('.spe', '*.spe')])\n",
    "    file_list = root.tk.splitlist(file_list) #workaround for Windows bug\n",
    "    root.destroy()\n",
    "    return file_list\n",
    "\n",
    "### Shirley background algorithm\n",
    "\n",
    "### Brief explanation of the algorithm: Shirley background is generated to be S(E) = y_min + interval * { A(2) / [A(1)+A(2)] }\n",
    "##  Where S(E) is the background intensity at a given binding energy E\n",
    "##  A(2) is the area at binding energies less than E, and A(1) is area at binding energies greater than E\n",
    "##  interval is usually accepted to be the intensity difference of the lower and upper bounds for binding energy, for our background region of interest\n",
    "##  This implementation first calculates the total area [A(1) + A(2)] by numerically integrating via the trapezoid method to find k_integral, and then k_val is simply \" interval / [A(1) + A(2)]\"\n",
    "##  Next we calculate A(2) (designated y_integral) and multiply it with k_val\n",
    "##  Once the iteration has completed, we add y_min to the background\n",
    "##  Tolerance is determined by calculating the norm of the difference of the initial and final background arrays. I don't understand how that works, but norm basically indicates the degree of difference between 2 arrays, so the smaller the norm, the higher tolerance. Unit is arbitrary, I think.\n",
    "def shirley_func(ind_min,ind_max,be_vals):\n",
    "    shirley_back = np.zeros(be_vals.shape)      ## initialize shirley_background array, same size as the entire domain of the region\n",
    "    for i in range(ind_min,ind_max+1):          ## populate shirley_back array with values for linear background\n",
    "        shirley_back[i] = ((y_max - y_min)/(x_max - x_min)) * (be_vals[i] - x_min)\n",
    "    shirley_back_it = shirley_back.copy()       ## copy shirley_back array for a separate, iterated/manipulated version\n",
    "\n",
    "    tol = 0.01      ## Tolerance level\n",
    "\n",
    "    it_max = 10       ## maximum number of iterations\n",
    "    it = 0              ## initial iteration value\n",
    "\n",
    "    while it < it_max:\n",
    "        k_integral = 0.0\n",
    "        for i in range(ind_max, ind_min):\n",
    "            k_integral += (be_vals[i+1] - be_vals[i]) * 0.5 * (intensity_vals[i+1] + intensity_vals[i] - 2 * y_min - shirley_back[i+1] - shirley_back[i]) # integration via trapezoid method\n",
    "        k_val = (y_max - y_min)/k_integral\n",
    "            \n",
    "        for i in range(ind_max, ind_min):\n",
    "            y_integral = 0.0\n",
    "            for j in range(i, ind_min):\n",
    "                y_integral += (be_vals[j+1] - be_vals[j]) * 0.5 * (intensity_vals[j+1] + intensity_vals[j] - 2 * y_min - shirley_back[j+1] - shirley_back[j])\n",
    "            shirley_back_it[i] = k_val * y_integral\n",
    "        \n",
    "        if np.linalg.norm(shirley_back_it - shirley_back) < tol:\n",
    "            shirley_back = shirley_back_it.copy()\n",
    "            break\n",
    "        else:\n",
    "            shirley_back = shirley_back_it.copy()\n",
    "        it +=1\n",
    "\n",
    "    if it >= it_max:\n",
    "        print(\"max iterations exceeded\")\n",
    "\n",
    "    shirley_back_fin = y_min + shirley_back\n",
    "\n",
    "    print(\"Number of iterations: \" + str(it))\n",
    "    return shirley_back_fin\n",
    "    # print(shirley_back_fin)\n",
    "\n",
    "    # print(shirley_back_fin)e(figsize=(10,5))\n",
    "\n",
    "### Gaussian\n",
    "def gauss(x,E,F,area,m):\n",
    "    # E = pars['E']\n",
    "    # F = pars['F']\n",
    "    # # a = param[2]\n",
    "    # m = pars['m']\n",
    "    # model = height* np.exp(-4 * np.log(2) * (1 - m/100) * ((x - E) / F)**2)\n",
    "    model = (2 * np.sqrt(np.log(2))/(F * np.sqrt(np.pi))) * area * np.exp(-4 * np.log(2) * (1 - m/100) * ((x - E) / F)**2)\n",
    "    return model\n",
    "\n",
    "# Note: for Gaussian, FWHM = 2 * sigma * sqrt(2 ln(2))\n",
    "\n",
    "### Lorentzian\n",
    "def lorentz(x,E,F,area,m):\n",
    "    # E = pars['E']\n",
    "    # F = pars['F']\n",
    "    # # a = param[2]\n",
    "    # m = pars['m']\n",
    "    # model = height / ((1 + 4 * m/100 * ((x - E) / F)**2))\n",
    "    model = 2 * area / (np.pi * (1 + 4 * m/100 * ((x - E) / F)**2) * F)\n",
    "    return model\n",
    "# !!!! I don't understand why this equation shouldn't be multiplied by 2. !!!!\n",
    "\n",
    "# Note: for Lorentzian, FWHM = 2 sigma\n",
    "\n",
    "### E = position (eV); F = FWHM; m = % Lorentzian\n",
    "\n",
    "### Sum G/L\n",
    "def sum_gl(x,E,F,area,m):\n",
    "    # E = param[0]\n",
    "    # F = param[1]\n",
    "    # a = param[2]\n",
    "    # m = param[3]\n",
    "    model = ((1-m/100) * gauss(x,E,F,area,0) + (m/100) * lorentz(x,E,F,area,100))\n",
    "    return model\n",
    "\n",
    "### Product G/L\n",
    "## Has issues with returning the correct area. I think it has to do with how the weight factor 'm' is incorporated. May need to do numerical integration.\n",
    "def product_gl(x,E,F,area,m):\n",
    "    # E = pars['E']\n",
    "    # F = pars['F']\n",
    "    # # a = param[2]\n",
    "    # m = pars['m']\n",
    "    model = (gauss(x,E,F,area,m) * lorentz(x,E,F,area,m))\n",
    "    return model\n",
    "\n",
    "### Defining default variable valus\n",
    "class xps_settings():\n",
    "    def __init__(self, region=\"C1s\", peak_type=\"singlet\", background_lower_bound=None, background_upper_bound=None, num_peaks=1, param=[284.5,1.0,100,80], peak_id=['p1_'], coup_E=None,coup_area=None, shift=0):\n",
    "        self.region = region\n",
    "        self.peak_type = peak_type\n",
    "        self.background_lower_bound = background_lower_bound\n",
    "        self.background_upper_bound = background_upper_bound\n",
    "        self.num_peaks = num_peaks\n",
    "        self.param = param\n",
    "        self.peak_id = peak_id\n",
    "        self.coup_E = coup_E\n",
    "        self.coup_area = coup_area\n",
    "        self.shift = shift\n",
    "\n",
    "# peak_type = \"couplets\"   # singlet or couplets\n",
    "# background_lower_bound = 24.8\n",
    "# # background_upper_bound = 37.25\n",
    "# num_peaks = 4\n",
    "# param = [[28,1.0,100,80],[30,1.0,100,80],[30,1.0,100,80],[33,1.0,100,80]]\n",
    "# peak_id = ['p1_','p1_2_','p2_','p2_2_']\n",
    "# coup_E = 1.91\n",
    "# coup_area = (3/4)\n",
    "\n",
    "# shift = -5.5\n",
    "\n",
    "# fwhm_min = 0\n",
    "# fwhm_max = 1.7\n",
    "# area_min = 0.1\n",
    "# gl_min = 0\n",
    "# gl_max = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1/4: Start here! Run the block below to import your SPE file and get a plot of the raw data.\n",
    "You can mouse over the plot to see the coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1623176511481,
     "user": {
      "displayName": "Hansen Mou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpX0kAdNL6lFvVSEqTwcLfrTvr1l-z768ZLhGZ=s64",
      "userId": "05725151348395746586"
     },
     "user_tz": 240
    },
    "id": "2Q1WtsQzm6SM",
    "outputId": "21c776a3-ed0b-4d52-fdc4-7e70c2a1d3e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SPE from C:/Users/hm115/Google Drive/Forschung/Data/XPS/XPS Data/Pt-TaN/210323-10%Pt-TaN(c-1)-fine0002.SPE\n",
      "Done!\n",
      "\n",
      "Regions identified: ['C1s', 'N1s', 'Ta4f', 'Pt4f7', 'O1s', 'In3d5']\n"
     ]
    }
   ],
   "source": [
    "### Import file\n",
    "file = get_file_names()\n",
    "\n",
    "data1 = XSpectrum()\n",
    "\n",
    "if len(file) > 0:\n",
    "    data1.load_spe(file[0])\n",
    "\n",
    "### Identify the regions in the imported file\n",
    "reg_len = len(data1._regions)\n",
    "label = []\n",
    "for i in range(reg_len):\n",
    "    label.append(data1._regions[i]['region_name'].decode('UTF-8'))\n",
    "print(\"\\nRegions identified: \" + str(label))\n",
    "\n",
    "### Assigning names to each set of data\n",
    "id_data1 = {}\n",
    "for i in range(reg_len):\n",
    "    id_data1[label[i]] = data1._regions[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Run below to see plots of your raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4535179983574677a62bb0ca6589e36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output(), Output(), Output(), Output()), _titles={'0': 'C1s', '1': 'N1s', '2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Plot the raw data\n",
    "%matplotlib widget\n",
    "sub_tab=[widgets.Output() for i in range(reg_len)]\n",
    "tab = widgets.Tab(sub_tab)\n",
    "for i in range(reg_len):\n",
    "    tab.set_title(i,label[i].format(i+1))\n",
    "    with sub_tab[i]:\n",
    "        fig = plt.figure(figsize=(10,5))\n",
    "        ax = fig.subplots()\n",
    "        ax.plot(data1._regions[i]['be_data'], data1._regions[i]['intensity'])\n",
    "        ax.set_title(label[i],fontweight='bold',fontsize=20)\n",
    "        ax.invert_xaxis()\n",
    "        ax.set_xlabel('Binding Energy [eV]',fontweight='bold',fontsize=16)\n",
    "        ax.set_ylabel('Intensity',fontweight='bold',fontsize=16)\n",
    "        ax.tick_params(axis='both',which='major',labelsize=14)\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(100))\n",
    "        plt.show(fig)\n",
    "display(tab)\n",
    "def mouse_move(event):\n",
    "    x, y = event.xdata, event.ydata\n",
    "    print(x, y)\n",
    "plt.connect('motion_notify_event', mouse_move)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2/4: Set your peak fitting configuration here\n",
    "## Make sure to comment out any options you don't want to set, but don't complain when things don't appear as you'd like.\n",
    "\n",
    "### Note: if peak_type = \"couplets\", then make sure number of parameters is half the number of peaks (since each parameter accounts for 2 peaks)\n",
    "\n",
    "Here's how the configuration works:\n",
    "\n",
    "peak\\_input = xps\\_settings( &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; This line initializes the peak configuration <br /><br />\n",
    "&emsp;&emsp;&emsp;&emsp;   region =  <br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Region name of interest. Make sure name is in \"quotes\". Default = \"C1s\" <br /><br />\n",
    "&emsp;&emsp;&emsp;&emsp;    peak\\_type = <br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Choose either \"singlet\" or \"couplets\" else the script will break. Default = \"singlet\" <br /><br />\n",
    "&emsp;&emsp;&emsp;&emsp;    background\\_lower\\_bound = <br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Pick the lower binding energy for the Shirley Background calculation to start at. Default = lower bound of region <br /><br />\n",
    "&emsp;&emsp;&emsp;&emsp;    background\\_upper\\_bound = <br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Pick the higher binding energy for the Shirley Background calculation to start at. Default = upper bound of region <br /><br />\n",
    "&emsp;&emsp;&emsp;&emsp;    num\\_peaks = <br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Number of peaks you want to fit in your region. Default = 1 <br /><br />\n",
    "&emsp;&emsp;&emsp;&emsp;    param = <br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Peak parameters. Format is as follows: \\[\\[Binding Energy, FWHM, Peak Area, % Gaussian/Lorentzian], ... ]. Default = \\[\\[284.5,1.0,100,80]]<br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Note: if peak\\_type = \"couplets\", then make sure number of parameters is half the number of peaks (since each parameter accounts for 2 peaks)<br /><br />\n",
    "&emsp;&emsp;&emsp;&emsp;    peak\\_id = <br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; List of peak ids for distinguising each peak. Label them however you will, but number of peak ids must be the same as the number for num_peaks. Default = ['p1_'] <br /><br />\n",
    "&emsp;&emsp;&emsp;&emsp;    coup\\_E = <br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Only used if peak_type = \"couplets\". This is the eV offset for the secondary peak relative to the main peak. Default = None <br /><br />\n",
    "&emsp;&emsp;&emsp;&emsp;    coup\\_area = <br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Only used if peak_type = \"couplets\". This is the area multiplier for the secondary peak relative to the main peak. Default = None <br /><br />\n",
    "&emsp;&emsp;&emsp;&emsp;    shift = <br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Used to shift the final plot by a number of eV. Useful if you know how far to adjust C1s peak, but otherwise you can set this at the end of the script as well. Default = 0 <br />\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### C1s\n",
    "# peak_input = xps_settings(\n",
    "#     region = \"C1s\",\n",
    "#     peak_type = \"singlet\",   # singlet or couplets\n",
    "#     background_lower_bound = 281.3,\n",
    "#     background_upper_bound = 295.85,\n",
    "#     num_peaks = 2,\n",
    "#     param = [[288.1,1.0,100,80],[290,1.0,100,80]],\n",
    "#     peak_id = ['p1_','p2_'],\n",
    "#     # shift = -4.5\n",
    "#     )\n",
    "\n",
    "### O1s\n",
    "# peak_input = xps_settings(\n",
    "#     region = \"O1s\",\n",
    "#     peak_type = \"singlet\",   # singlet or couplets\n",
    "#     background_lower_bound = 530.2,\n",
    "#     background_upper_bound = 541.5,\n",
    "#     num_peaks = 2,\n",
    "#     param = [[535.45,1.0,100,80],[537.6,1.0,100,80]],\n",
    "#     peak_id = ['p1_','p2_'],\n",
    "#     # shift = -4.5\n",
    "#     )\n",
    "\n",
    "### Pt4f7 \n",
    "# peak_input = xps_settings(\n",
    "#     region = \"Pt4f7\",\n",
    "#     peak_type = \"couplets\",   # singlet or couplets\n",
    "#     background_lower_bound = 69.65,\n",
    "#     background_upper_bound = 86.95,\n",
    "#     num_peaks = 2,\n",
    "#     param = [[74.6,1.0,100,80],[78,1.0,100,80],[76,1.0,100,80],[79,1.0,100,80]],\n",
    "#     peak_id = ['p1_','p1_2_','p2_','p2_2_'],\n",
    "#     coup_E = 3.33,\n",
    "#     coup_area = (3/4),\n",
    "#     # shift = -4.7\n",
    "#     )\n",
    "\n",
    "### Pd3d\n",
    "# peak_input = xps_settings(\n",
    "#     region = \"Pd3d\",\n",
    "#     peak_type = \"couplets\",   # singlet or couplets\n",
    "#     background_lower_bound = 335.1,\n",
    "#     background_upper_bound = 349.95,\n",
    "#     num_peaks = 4,\n",
    "#     param = [[341,1.0,100,80],[341.2,1.0,100,80],[341.9,1.0,100,80],[346.2,1.0,100,80]],\n",
    "#     peak_id = ['p1_','p1_2_','p2_','p2_2_'],\n",
    "#     coup_E = 5.26,\n",
    "#     coup_area = (2/3),\n",
    "#     shift = -5.5,\n",
    "#     )\n",
    "\n",
    "###  Nb3d\n",
    "# peak_input = xps_settings(\n",
    "#     region = \"Nb3d\",\n",
    "#     peak_type = \"couplets\",   # singlet or couplets\n",
    "#     background_lower_bound = 205,\n",
    "#     # background_upper_bound = 349.95,\n",
    "#     num_peaks = 4,\n",
    "#     param = [[207.9,1.0,100,80],[211.4,1.0,100,80],[212,1.0,100,80],[214.7,1.0,100,80]],\n",
    "#     peak_id = ['p1_','p1_2_','p2_','p2_2_'],\n",
    "#     coup_E = 2.72,\n",
    "#     coup_area = (2/3),\n",
    "#     # shift = -4.5,\n",
    "#     )\n",
    "\n",
    "### Ta4f\n",
    "peak_input = xps_settings(\n",
    "    region = \"Ta4f\",\n",
    "    peak_type = \"couplets\",   # singlet or couplets\n",
    "    background_lower_bound = 25.3,\n",
    "    background_upper_bound = 36.5,\n",
    "    num_peaks = 6,\n",
    "    param = [[29,1.0,100,80],[27,1.0,100,80],[31,1.0,100,80]],\n",
    "    peak_id = ['p1_','p1_2_','p2_','p2_2_','p3_','p3_2_'],\n",
    "    coup_E = 1.91,\n",
    "    coup_area = (3/4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Calculate Shirley Background and plot initial guesses\n",
    "### Start running the blocks below once satisfied with the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30521,
     "status": "ok",
     "timestamp": 1617823691188,
     "user": {
      "displayName": "Hansen Mou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpX0kAdNL6lFvVSEqTwcLfrTvr1l-z768ZLhGZ=s64",
      "userId": "05725151348395746586"
     },
     "user_tz": 240
    },
    "id": "Q63bMGS_MOtK",
    "outputId": "26ef5fc9-1781-4004-e57b-9c934d7d13c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ta4f loaded!\n",
      "Done!\n",
      "Number of iterations: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817231c7a5424965b3287c6ef1e56617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "which_reg = peak_input.region\n",
    "\n",
    "if peak_input.region not in id_data1:\n",
    "    print(\"The region you chose is not present. Please choose from the following:\")\n",
    "    for i in id_data1:\n",
    "        print(\"\\t\"+str(i))\n",
    "else: \n",
    "    be_vals = id_data1[peak_input.region]['be_data']\n",
    "    activ_reg = label.index(peak_input.region)\n",
    "    intensity_vals = id_data1[peak_input.region]['intensity']\n",
    "    print(str(peak_input.region) + \" loaded!\")\n",
    "    ### Setting background\n",
    "    if peak_input.background_lower_bound is None:\n",
    "        peak_input.background_lower_bound = be_vals[-1]\n",
    "    if peak_input.background_upper_bound is None:\n",
    "        peak_input.background_upper_bound = be_vals[0]\n",
    "\n",
    "    x_min = be_vals[np.abs(be_vals - peak_input.background_lower_bound).argmin()]\n",
    "    x_max = be_vals[np.abs(be_vals - peak_input.background_upper_bound).argmin()]\n",
    "    if x_min > x_max:\n",
    "        print(\"Please switch your upper and lower bounds.\")\n",
    "    elif x_max not in be_vals or x_min not in be_vals:\n",
    "        print(\"Your selected bounds exceed the region. Please set bounds between \" + str(be_vals[-1]) + \" and \" + str(be_vals[0]))\n",
    "    else:\n",
    "        ind_min = np.where(be_vals == x_min)[0][0]\n",
    "        ind_max = np.where(be_vals == x_max)[0][0]\n",
    "\n",
    "        y_min = id_data1[which_reg]['intensity'][ind_min]\n",
    "        y_max = id_data1[which_reg]['intensity'][ind_max]\n",
    "\n",
    "        print(\"Done!\")\n",
    "\n",
    "        shirley_back_fin = shirley_func(ind_min, ind_max, be_vals)\n",
    "\n",
    "        ### Plotting initial parameters\n",
    "        ### param = [peak binding energy, FWHM, area, % gauss/lorentz]\n",
    "\n",
    "        if peak_input.num_peaks is None:\n",
    "            num_peaks = 2\n",
    "\n",
    "        if peak_input.param is None:\n",
    "            param = [[74.6,1.0,100,80],[78,1.0,100,80]]\n",
    "\n",
    "        ### if fitting couplets, only need half as many parameters as peaks\n",
    "\n",
    "        ### Normalizing and zeroing the raw data for fitting\n",
    "        i = activ_reg\n",
    "\n",
    "        intensity_zeroed = np.zeros(be_vals.shape)\n",
    "\n",
    "        for j in range(len(be_vals)):\n",
    "            intensity_zeroed[j] = intensity_vals[j] - shirley_back_fin[j]\n",
    "\n",
    "        norm_factor = np.max(intensity_zeroed)\n",
    "\n",
    "        intensity_norm = intensity_zeroed / norm_factor    \n",
    "\n",
    "        ### Plots the initial guess on the figure\n",
    "        initial_fit = []\n",
    "        if peak_input.peak_type == \"couplets\":\n",
    "            for i in range(peak_input.num_peaks):\n",
    "                if i % 2 == 0:\n",
    "                    initial_fit.append(sum_gl(be_vals[ind_max:ind_min],*peak_input.param[int(i/2)]) + shirley_back_fin[ind_max:ind_min])\n",
    "                else:\n",
    "                    coupled_param = [peak_input.param[int((i-1)/2)][0] + peak_input.coup_E, peak_input.param[int((i-1)/2)][1], peak_input.param[int((i-1)/2)][2] * peak_input.coup_area, peak_input.param[int((i-1)/2)][3]]\n",
    "                    initial_fit.append(sum_gl(be_vals[ind_max:ind_min],*coupled_param) + shirley_back_fin[ind_max:ind_min])\n",
    "        elif peak_input.peak_type == \"singlet\":\n",
    "            for i in range(peak_input.num_peaks):\n",
    "                initial_fit.append(sum_gl(be_vals[ind_max:ind_min],*peak_input.param[i]) + shirley_back_fin[ind_max:ind_min])\n",
    "\n",
    "        initial_fit = np.array(initial_fit)\n",
    "\n",
    "        # make sure that you multiply the shirley_back_fin by (total number of initial fits minus 1!)\n",
    "        initial_fit_sum = 0\n",
    "        initial_fit_sum = np.sum(initial_fit,axis=0) - (peak_input.num_peaks-1) * shirley_back_fin[ind_max:ind_min]\n",
    "\n",
    "        fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        ax.plot(be_vals, intensity_vals)       ## Plot Region in question\n",
    "        ax.plot(be_vals[ind_max:ind_min],shirley_back_fin[ind_max:ind_min])    ## Plot Shirley background\n",
    "        ax.plot(be_vals[ind_max:ind_min],initial_fit_sum)        ## Initial Fit\n",
    "        for i in range(len(initial_fit)):\n",
    "            ax.plot(be_vals[ind_max:ind_min],initial_fit[i])        ## Initial Fit\n",
    "\n",
    "        ax.set_title(label[activ_reg],fontweight='bold',fontsize=20)\n",
    "        ax.invert_xaxis()\n",
    "        ax.set_xlabel('Binding Energy [eV]',fontweight='bold',fontsize=16)\n",
    "        ax.set_ylabel('Intensity',fontweight='bold',fontsize=16)\n",
    "        ax.tick_params(axis='both',which='major',labelsize=14)\n",
    "        fig.subplots_adjust(hspace = 0.4)\n",
    "\n",
    "        # plt.legend(['data', 'background', 'initial guess', 'final fit'])\n",
    "        plt.legend(['data', 'background', 'overall fit'])\n",
    "\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(100))\n",
    "\n",
    "        # ax[0].set_ylim(400,480)\n",
    "        # ax[1].set_ylim(0,500)\n",
    "\n",
    "        def mouse_move(event):\n",
    "            x, y = event.xdata, event.ydata\n",
    "            print(x, y)\n",
    "\n",
    "        plt.connect('motion_notify_event', mouse_move)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sep 4: Once satisfied with the initial guess, run the next block to fit the peaks\n",
    "Note: need to clean up the parameters output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters([('p1_E', <Parameter 'p1_E', value=29, bounds=[-inf:inf]>), ('p1_F', <Parameter 'p1_F', value=1.0, bounds=[0:1.7]>), ('p1_area', <Parameter 'p1_area', value=100, bounds=[0.1:inf]>), ('p1_m', <Parameter 'p1_m', value=80, bounds=[0:100]>), ('p1_2_E', <Parameter 'p1_2_E', value=30.91, bounds=[-inf:inf], expr='p1_E + 1.91'>), ('p1_2_F', <Parameter 'p1_2_F', value=1.0, bounds=[-inf:inf], expr='p1_F'>), ('p1_2_area', <Parameter 'p1_2_area', value=75.0, bounds=[-inf:inf], expr='p1_area * 0.75'>), ('p1_2_m', <Parameter 'p1_2_m', value=80, bounds=[-inf:inf], expr='p1_m'>), ('p2_E', <Parameter 'p2_E', value=27, bounds=[-inf:inf]>), ('p2_F', <Parameter 'p2_F', value=1.0, bounds=[0:1.7]>), ('p2_area', <Parameter 'p2_area', value=100, bounds=[0.1:inf]>), ('p2_m', <Parameter 'p2_m', value=80, bounds=[0:100]>), ('p2_2_E', <Parameter 'p2_2_E', value=28.91, bounds=[-inf:inf], expr='p2_E + 1.91'>), ('p2_2_F', <Parameter 'p2_2_F', value=1.0, bounds=[-inf:inf], expr='p2_F'>), ('p2_2_area', <Parameter 'p2_2_area', value=75.0, bounds=[-inf:inf], expr='p2_area * 0.75'>), ('p2_2_m', <Parameter 'p2_2_m', value=80, bounds=[-inf:inf], expr='p2_m'>), ('p3_E', <Parameter 'p3_E', value=31, bounds=[-inf:inf]>), ('p3_F', <Parameter 'p3_F', value=1.0, bounds=[0:1.7]>), ('p3_area', <Parameter 'p3_area', value=100, bounds=[0.1:inf]>), ('p3_m', <Parameter 'p3_m', value=80, bounds=[0:100]>), ('p3_2_E', <Parameter 'p3_2_E', value=32.91, bounds=[-inf:inf], expr='p3_E + 1.91'>), ('p3_2_F', <Parameter 'p3_2_F', value=1.0, bounds=[-inf:inf], expr='p3_F'>), ('p3_2_area', <Parameter 'p3_2_area', value=75.0, bounds=[-inf:inf], expr='p3_area * 0.75'>), ('p3_2_m', <Parameter 'p3_2_m', value=80, bounds=[-inf:inf], expr='p3_m'>)])\n"
     ]
    }
   ],
   "source": [
    "peak_param_id = ['E','F','area','m']\n",
    "\n",
    "fwhm_min = 0\n",
    "fwhm_max = 1.7\n",
    "area_min = 0.1\n",
    "gl_min = 0\n",
    "gl_max = 100\n",
    "\n",
    "peak_model_list = []\n",
    "peak_model_list.append(Model(sum_gl,prefix=peak_input.peak_id[0]))\n",
    "pars = peak_model_list[0].make_params()\n",
    "\n",
    "pars[peak_input.peak_id[0]+peak_param_id[0]].set(value=peak_input.param[0][0])\n",
    "pars[peak_input.peak_id[0]+peak_param_id[1]].set(value=peak_input.param[0][1],min=0,max=1.7)\n",
    "pars[peak_input.peak_id[0]+peak_param_id[2]].set(value=peak_input.param[0][2],min=0.1)\n",
    "pars[peak_input.peak_id[0]+peak_param_id[3]].set(value=peak_input.param[0][3],min=0,max=100)\n",
    "\n",
    "if peak_input.peak_type == \"singlet\":\n",
    "    for i in range(1,peak_input.num_peaks):\n",
    "        peak_model_list.append(Model(sum_gl,prefix=peak_input.peak_id[i]))\n",
    "        pars.update(peak_model_list[i].make_params())\n",
    "\n",
    "        pars[peak_input.peak_id[i]+peak_param_id[0]].set(value=peak_input.param[i][0])\n",
    "        pars[peak_input.peak_id[i]+peak_param_id[1]].set(value=peak_input.param[i][1],min=0,max=1.7)\n",
    "        pars[peak_input.peak_id[i]+peak_param_id[2]].set(value=peak_input.param[i][2],min=0.1)\n",
    "        pars[peak_input.peak_id[i]+peak_param_id[3]].set(value=peak_input.param[i][3],min=0,max=100)\n",
    "elif peak_input.peak_type == \"couplets\":\n",
    "    for i in range(1,peak_input.num_peaks):\n",
    "        peak_model_list.append(Model(sum_gl,prefix=peak_input.peak_id[i]))\n",
    "        pars.update(peak_model_list[i].make_params())\n",
    "        if i % 2 == 0:\n",
    "            pars[peak_input.peak_id[i]+peak_param_id[0]].set(value=peak_input.param[int(i/2)][0])\n",
    "            pars[peak_input.peak_id[i]+peak_param_id[1]].set(value=peak_input.param[int(i/2)][1],min=0,max=1.7)\n",
    "            pars[peak_input.peak_id[i]+peak_param_id[2]].set(value=peak_input.param[int(i/2)][2],min=0.1)\n",
    "            pars[peak_input.peak_id[i]+peak_param_id[3]].set(value=peak_input.param[int(i/2)][3],min=0,max=100)\n",
    "        else:\n",
    "            ### Set how the parameters for peak2_2 are bound by peak 2\n",
    "\n",
    "            # peak binding energy\n",
    "            pars[peak_input.peak_id[i]+peak_param_id[0]].set(expr=peak_input.peak_id[i-1]+peak_param_id[0]+ ' + ' + str(peak_input.coup_E))\n",
    "\n",
    "            # peak FWHM\n",
    "            pars[peak_input.peak_id[i]+peak_param_id[1]].set(expr=peak_input.peak_id[i-1]+peak_param_id[1])\n",
    "\n",
    "            # peak area (could probably automate this by extracting the orbital from the region name)\n",
    "            pars[peak_input.peak_id[i]+peak_param_id[2]].set(expr=peak_input.peak_id[i-1]+peak_param_id[2] + ' * ' + str(peak_input.coup_area))\n",
    "\n",
    "            # % GL\n",
    "            pars[peak_input.peak_id[i]+peak_param_id[3]].set(expr=peak_input.peak_id[i-1]+peak_param_id[3])\n",
    "                \n",
    "print(pars)\n",
    "# print(peak_model_list)\n",
    "peaks_all = np.array(peak_model_list)\n",
    "model = np.sum(peaks_all,axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5/6: Run this block to perform the fit.\n",
    "### Check the \"\\[\\[Variables]]\" section of the output for the fitted parameters\n",
    "\n",
    "Need to format the output, include the shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    (((((Model(sum_gl, prefix='p1_') + Model(sum_gl, prefix='p1_2_')) + Model(sum_gl, prefix='p2_')) + Model(sum_gl, prefix='p2_2_')) + Model(sum_gl, prefix='p3_')) + Model(sum_gl, prefix='p3_2_'))\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = least_squares\n",
      "    # function evals   = 24\n",
      "    # data points      = 224\n",
      "    # variables        = 12\n",
      "    chi-square         = 9940.17993\n",
      "    reduced chi-square = 46.8876412\n",
      "    Akaike info crit   = 873.563534\n",
      "    Bayesian info crit = 914.503287\n",
      "[[Variables]]\n",
      "    p1_E:       29.8029800 +/- 0.23714228 (0.80%) (init = 29)\n",
      "    p1_F:       1.70000000 +/- 0.90372846 (53.16%) (init = 1)\n",
      "    p1_area:    86.8731338 +/- 117.457110 (135.21%) (init = 100)\n",
      "    p1_m:       1.2491e-31 +/- 197.785975 (158338448522808273038873573093015552.00%) (init = 80)\n",
      "    p1_2_E:     31.7129800 +/- 0.23714228 (0.75%) == 'p1_E + 1.91'\n",
      "    p1_2_F:     1.70000000 +/- 0.90372846 (53.16%) == 'p1_F'\n",
      "    p1_2_area:  65.1548503 +/- 88.0928328 (135.21%) == 'p1_area * 0.75'\n",
      "    p1_2_m:     1.2491e-31 +/- 197.785976 (158338448957217991034801140499742720.00%) == 'p1_m'\n",
      "    p2_E:       28.1177164 +/- 0.20801656 (0.74%) (init = 27)\n",
      "    p2_F:       1.70000000 +/- 0.29714901 (17.48%) (init = 1)\n",
      "    p2_area:    104.771358 +/- 51.0242700 (48.70%) (init = 100)\n",
      "    p2_m:       59.1430738 +/- 35.6332170 (60.25%) (init = 80)\n",
      "    p2_2_E:     30.0277164 +/- 0.20801656 (0.69%) == 'p2_E + 1.91'\n",
      "    p2_2_F:     1.70000000 +/- 0.29714901 (17.48%) == 'p2_F'\n",
      "    p2_2_area:  78.5785188 +/- 38.2682025 (48.70%) == 'p2_area * 0.75'\n",
      "    p2_2_m:     59.1430738 +/- 35.6332170 (60.25%) == 'p2_m'\n",
      "    p3_E:       31.3045343 +/- 0.10012541 (0.32%) (init = 31)\n",
      "    p3_F:       1.70000000 +/- 0.10930557 (6.43%) (init = 1)\n",
      "    p3_area:    318.507229 +/- 63.9952851 (20.09%) (init = 100)\n",
      "    p3_m:       17.2448069 +/- 18.6795352 (108.32%) (init = 80)\n",
      "    p3_2_E:     33.2145343 +/- 0.10012541 (0.30%) == 'p3_E + 1.91'\n",
      "    p3_2_F:     1.70000000 +/- 0.10930557 (6.43%) == 'p3_F'\n",
      "    p3_2_area:  238.880422 +/- 47.9964640 (20.09%) == 'p3_area * 0.75'\n",
      "    p3_2_m:     17.2448069 +/- 18.6795352 (108.32%) == 'p3_m'\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(p1_area, p3_area) = -0.982\n",
      "    C(p1_area, p2_area) = -0.976\n",
      "    C(p3_E, p3_F)       = -0.959\n",
      "    C(p1_F, p2_E)       = -0.959\n",
      "    C(p1_E, p3_F)       = -0.931\n",
      "    C(p2_area, p3_area) =  0.921\n",
      "    C(p1_F, p3_E)       =  0.915\n",
      "    C(p1_F, p3_area)    = -0.915\n",
      "    C(p2_E, p2_F)       =  0.911\n",
      "    C(p1_E, p3_E)       =  0.892\n",
      "    C(p1_m, p2_area)    = -0.885\n",
      "    C(p1_F, p3_F)       = -0.867\n",
      "    C(p1_F, p1_area)    =  0.866\n",
      "    C(p1_F, p2_F)       = -0.858\n",
      "    C(p1_m, p3_m)       = -0.857\n",
      "    C(p2_E, p3_area)    =  0.843\n",
      "    C(p2_E, p3_E)       = -0.838\n",
      "    C(p1_area, p1_m)    =  0.828\n",
      "    C(p1_area, p2_E)    = -0.814\n",
      "    C(p1_F, p2_area)    = -0.780\n",
      "    C(p1_area, p2_F)    = -0.776\n",
      "    C(p2_F, p3_area)    =  0.773\n",
      "    C(p2_E, p3_F)       =  0.765\n",
      "    C(p2_E, p2_area)    =  0.760\n",
      "    C(p2_F, p2_area)    =  0.755\n",
      "    C(p3_E, p3_area)    = -0.745\n",
      "    C(p3_F, p3_area)    =  0.744\n",
      "    C(p1_m, p3_area)    = -0.735\n",
      "    C(p1_E, p1_F)       =  0.699\n",
      "    C(p2_F, p3_E)       = -0.676\n",
      "    C(p1_area, p3_F)    = -0.640\n",
      "    C(p1_area, p3_E)    =  0.639\n",
      "    C(p2_area, p3_m)    =  0.603\n",
      "    C(p1_m, p2_m)       = -0.595\n",
      "    C(p2_F, p3_F)       =  0.591\n",
      "    C(p2_m, p3_m)       =  0.570\n",
      "    C(p1_E, p2_E)       = -0.559\n",
      "    C(p1_E, p3_area)    = -0.557\n",
      "    C(p1_area, p3_m)    = -0.520\n",
      "    C(p2_area, p3_E)    = -0.503\n",
      "    C(p2_area, p3_F)    =  0.500\n",
      "    C(p1_m, p2_F)       = -0.455\n",
      "    C(p1_F, p1_m)       =  0.439\n",
      "    C(p1_E, p1_area)    =  0.428\n",
      "    C(p3_area, p3_m)    =  0.426\n",
      "    C(p1_E, p3_m)       =  0.423\n",
      "    C(p1_m, p2_E)       = -0.400\n",
      "    C(p2_area, p2_m)    =  0.348\n",
      "    C(p2_m, p3_E)       =  0.345\n",
      "    C(p1_E, p2_F)       = -0.321\n",
      "    C(p2_F, p2_m)       = -0.283\n",
      "    C(p1_E, p2_area)    = -0.269\n",
      "    C(p3_E, p3_m)       =  0.252\n",
      "    C(p3_F, p3_m)       = -0.251\n",
      "    C(p2_m, p3_F)       = -0.241\n",
      "    C(p2_E, p2_m)       = -0.239\n",
      "    C(p1_area, p2_m)    = -0.225\n",
      "    C(p1_E, p2_m)       =  0.216\n",
      "    C(p2_F, p3_m)       =  0.216\n",
      "    C(p1_F, p2_m)       =  0.187\n",
      "    C(p1_m, p3_F)       = -0.152\n",
      "    C(p2_m, p3_area)    =  0.120\n",
      "    C(p1_m, p3_E)       =  0.110\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(intensity_zeroed[ind_max:ind_min],pars,x=be_vals[ind_max:ind_min],method=\"Least_squares\")\n",
    "\n",
    "print(fit.fit_report())\n",
    "\n",
    "final = (fit.best_fit) + shirley_back_fin[ind_max:ind_min]\n",
    "comps = fit.eval_components(x=be_vals[ind_max:ind_min])\n",
    "\n",
    "for i in peak_input.peak_id[:peak_input.num_peaks]:\n",
    "    comps[i] = comps[i] + shirley_back_fin[ind_max:ind_min]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6/6: Run this block to plot the fit. You may have to change the labels and such.\n",
    "### Adjust the shift by changing peak_input.shift\n",
    "Note: add auto-labeling for the sub-peaks, maybe via an additional parameter? Also make the shift more intuitive and user-friendly. Also make colors more easily configurable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da20570d71554847aa92bae2d203792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Uncomment the next line to adjust the shift\n",
    "# peak_input.shift = 0\n",
    "\n",
    "x_min_shift = x_min + peak_input.shift\n",
    "x_max_shift = x_max + peak_input.shift\n",
    "\n",
    "be_vals_shift = be_vals + peak_input.shift\n",
    "\n",
    "fig = plt.figure(figsize=(7,5.5))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "ax.plot(be_vals_shift, intensity_vals, color='grey')       ## Plot Region in question\n",
    "ax.plot(be_vals_shift[ind_max:ind_min],shirley_back_fin[ind_max:ind_min])    ## Plot Shirley background\n",
    "\n",
    "ax.plot(be_vals_shift[ind_max:ind_min], final, linewidth=3)    ## Final Fit\n",
    "\n",
    "for i in range(peak_input.num_peaks):\n",
    "    ax.plot(be_vals_shift[ind_max:ind_min],comps[peak_input.peak_id[i]], label=peak_input.peak_id[i], linewidth=3)\n",
    "\n",
    "ax.set_title(label[activ_reg],fontweight='bold',fontsize=20)\n",
    "\n",
    "ax.set_xlim(x_min_shift,x_max_shift)\n",
    "\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('Binding Energy [eV]',fontweight='bold',fontsize=16)\n",
    "ax.set_ylabel('Intensity',fontweight='bold',fontsize=16)\n",
    "ax.tick_params(axis='both',which='major',labelsize=14)\n",
    "fig.subplots_adjust(hspace = 0.4)\n",
    "\n",
    "plt.legend(['Data', 'Background', 'Fit'],fontsize=10,loc=\"upper left\")\n",
    "\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(100))\n",
    "\n",
    "def mouse_move(event):\n",
    "    x, y = event.xdata, event.ydata\n",
    "    print(x, y)\n",
    "\n",
    "plt.connect('motion_notify_event', mouse_move)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're done! I haven't implemented a way to export the data yet, so just copy the plot and the results into powerpoint or something.\n",
    "\n",
    "Please email me at h.mou@columbia.edu or on Slack with any questions or bugs to report.\n",
    "\n",
    "Known issues:\n",
    "- using product_gl method doesn't provide accurate areas\n",
    "- no way to easily export the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now I have to zero & normalize the raw data, because the fit equations max out at 1 and start at 0 intensity, before fitting. Then I undo everything to move the fitted plot onto the original raw data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Updated-tgmeow_Read and Plot Spectrum Data.ipynb",
   "provenance": [
    {
     "file_id": "1-S9JK9aqv0B8-4G2iEovSZROuiCqWdU8",
     "timestamp": 1616527773421
    },
    {
     "file_id": "1RsPw2ZW0Z3LYVccJtxjC3FfbDIODYQ40",
     "timestamp": 1616526980863
    }
   ]
  },
  "interpreter": {
   "hash": "5a609d29712f46cb739538e77019f71abfad367d089f9415cf30babbf69751d1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
